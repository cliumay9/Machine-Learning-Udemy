6-3
2+5
winners <- read.delim(pipe('pbpaste'))
View(winners)
View(winners)
winners
winners <- read.delim(pipe('pbpaste'))
View(winners)
winners
x+y
x<- 1
y<-2
x+y
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
Oscar
Romeo+Oscar
Calvin<-Romeo+Oscar
Calvin<-x
Oscar
source('~/.active-rstudio-document', echo=TRUE)
Juliet-Romeo
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/Downloads/Ex_Files_Intro_Data_Science/DataScienceExcercise_github/Ensembles with Random Forest.R')
source('~/.active-rstudio-document')
install.packages("randomForest")
install.packages("party")  # Install party
library(datasets)          # Load built-in datasets
library(party)             # Load party
head(iris)
iris.ct <- ctree(Species~., data=iris)
plot(iris.ct)
table(predict(iris.ct),iris$Species)
head(mtcars)
car.rt<-ctree(mpg~cyl+disp+hp+drat+wt+qsec, data=mtcars)
plot(car.rt2)
plot(car.rt3)
plot(car.rt)
table(predict(car.rt),mtcars$mpg)
data(HouseVotes84, package = "mlbench")
vote <- HouseVotes84
head(vote)
set.seed(1984)
set.seed(1984)
vote.split <- sample(2, nrow(vote),
replace = TRUE,
prob = c(2/3, 1/3))
vote.train <- vote[vote.split == 1, ]
vote.test  <- vote[vote.split == 2, ]
# ==========================================================
# Build and test classifier
# nbc= naive Bayes Classifier
# ==========================================================
nbc <- naiveBayes(Class ~ ., data = vote.train)
install.packages("e1071")
install.packages("mlbench")
library(e1071)
library(mlbench)
# ==========================================================
# Prepare data: HouseVotes84
# Using "HouseVotes84" from mlbench package
# ==========================================================
data(HouseVotes84, package = "mlbench")
vote <- HouseVotes84
head(vote)
# Split data into training set (2/3) and testing set (1/3)
# set.seed()to have consistency
# Trying to categorize whether one person is democrat or republican
# Split data with 2 sets: a training set and a testing set (WITH vote.split)
set.seed(1984)
vote.split <- sample(2, nrow(vote),
replace = TRUE,
prob = c(2/3, 1/3))
vote.train <- vote[vote.split == 1, ]
vote.test  <- vote[vote.split == 2, ]
head(vote.train)
head(vote.test)
nbc <- naiveBayes(Class ~ ., data = vote.train)
nbc  # Examine the classifier
table(predict(nbc, vote.train[, -1]), vote.train[, 1])
round(prop.table(table(predict(nbc, vote.train[, -1]),
vote.train[, 1]),
1),  # Row percentages (2 = column)
2) * 100        # Round to 2 digits, remove decimals
table(predict(nbc, vote.test[, -1]), vote.test[, 1])
round(prop.table(table(predict(nbc, vote.test[, -1]),
vote.test[, 1]),
1),  # Row percentages (2 = column)
2) * 100        # Round to 2 digits, remove decimals
rm(list = ls())
detach("package:e1071", unload = TRUE)
detach("package:mlbench", unload = TRUE)
cat("\014")
install.packages('neuralnet')  # Install neuralnet
library(neuralnet)             # Load neuralnet
set.seed(1202)                             # Set seed
train.x <- sample(1:100, 50, replace = T)
head(train.x)
train.x
train.y <- sqrt(train.x)
train y
train.y
train.xy <- as.data.frame(cbind(train.x, train.y))
head(train.xy)
net.sqrt <- neuralnet(train.y ~ train.x,
train.xy,
hidden = 10,
threshold = 0.01)
plot(net.sqrt)
hidden = 20,
net.sqrt <- neuralnet(train.y ~ train.x,
train.xy,
hidden = 20,
threshold = 0.01)
plot(net.sqrt)
test.x <- as.data.frame((1:10)^2)
test.y <- compute(net.sqrt, test.x)
test.y
test.x
test.y
net.table <- cbind(test.x,
sqrt(test.x),
round(test.y$net.result, 2))
net.table
net.table <- cbind(test.x,
sqrt(test.x),
round(test.y$net.result, 3))
colnames(net.table) <- c("X","Y-Exp","Y-ANN")
net.table  # Display table
test.trainx <- comput(net.sqrt, train.x)
test.trainx <- compute(net.sqrt, train.x)
test.trainx
train.y
#
test.trainx
train.y
net.table<- cbind(train.x, train.y, round(test.trainx$net.result,3))
net.table1<- cbind(train.x, train.y, round(test.trainx$net.result,3))
net.table <- cbind(test.x,
sqrt(test.x),
round(test.y$net.result, 3))
net.table1
net.table <- cbind(test.x,
sqrt(test.x),
round(test.y$net.result, 3))
colnames(net.table) <- c("X","Y-Exp","Y-ANN")
#Rename the column name
net.table  # Display table
net.table
test.y
print("Hello World!")
print("Hello World")
setwd("~/Desktop/Ex_Files_DSF_DataMining/Machine-Learning-Udemy/Polynomial Regression")
dataset = read.csv('Position_Salaries.csv')
View(dataset)
View(dataset)
dataset = dataset[:,2:3]
dataset = dataset[2:3]
View(dataset)
View(dataset)
# Poly Regression
## Beginning of Data Preprocessing ##
dataset = read.csv('Position_Salaries.csv')
# Reset the dataset because we don't need the first column
dataset = dataset[2:3] # Ignore first column
## END of Data Preprocessing ##
## Fitting Linear regression to the dataset
lin_reg = lm(forumula = Salary ~ ., data= dataset)
summary(lin_reg)
dataset$Level2 = (data$Level)^2
poly_reg = lm(Salary ~., data = dataset)
View(dataset)
dataset$Level2 = (data$Level)^2
dataset$Level2 = (dataset$Level)^2
View(dataset)
dataset$Level2 = (dataset$Level)^2
dataset$Level3 = (dataset$Level)^3
dataset$Level4 = (dataset$Level)^4
poly_reg = lm(Salary ~., data = dataset)
summary(lin_reg)
install.packages("ggplot2")
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library(ggplot2)
library(ggplot2)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = dataset$Level, y = predict(lin_reg, newdata = dataset)),
colour = 'blue') +
ggtitle('Salary vs Level (Linear Regression)')+
xlab('Level')+
ylab('Salary')
View(dataset)
# Poly Regression
## Beginning of Data Preprocessing ##
dataset = read.csv('Position_Salaries.csv')
# Reset the dataset because we don't need the first column
dataset = dataset[2:3] # Ignore first column
## END of Data Preprocessing ##
## Fitting Linear regression to the dataset
lin_reg = lm(Salary ~ ., data = dataset)
## FItting Poly Regression to the dataset
# Add column into the dataset
dataset$Level2 = (dataset$Level)^2
dataset$Level3 = (dataset$Level)^3
dataset$Level4 = (dataset$Level)^4
poly_reg = lm(Salary ~., data = dataset)
# Visualizing the Linear Regression results
# install.packages('ggplot2) if you dont have ggplot2 installed
library(ggplot2)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = dataset$Level, y = predict(lin_reg, newdata = dataset)),
colour = 'blue') +
ggtitle('Salary vs Level (Linear Regression)')+
xlab('Level')+
ylab('Salary')
# Visualizing the Poly Regression results
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = dataset$Level, y = predict(lin_reg, newdata = dataset)),
colour = 'blue') +
ggtitle('Salary vs Level (Linear Regression)')+
xlab('Level')+
ylab('Salary')
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = dataset$Level, y = predict(poly_reg, newdata = dataset)),
colour = 'blue') +
ggtitle('Salary vs Level (Poly Regression)')+
xlab('Level')+
ylab('Salary')
predict(lin_reg, 6.5)
y_pred = predict(lin_reg, data.frame(Level = 6.5))
y_poly_red = predict(poly_reg, data.frame(Level = 6.5))
y_poly_red = predict(poly_reg, data.frame(Level = 6.5, Level2= 6.5^2, Level3= 6.5^3, Level4=6.5^4))
y_poly_red = predict(poly_reg, data.frame(Level = 6.5,
Level2= 6.5^2,
Level3= 6.5^3,
Level4=6.5^4))
# Poly Regression
## Beginning of Data Preprocessing ##
dataset = read.csv('Position_Salaries.csv')
# Reset the dataset because we don't need the first column
dataset = dataset[2:3] # Ignore first column
## END of Data Preprocessing ##
## Fitting Linear regression to the dataset
lin_reg = lm(Salary ~ ., data = dataset)
## FItting Poly Regression to the dataset
# Add column into the dataset
dataset$Level2 = (dataset$Level)^2
dataset$Level3 = (dataset$Level)^3
dataset$Level4 = (dataset$Level)^4
poly_reg = lm(Salary ~., data = dataset)
# Visualizing the Linear Regression results
# install.packages('ggplot2) if you dont have ggplot2 installed
library(ggplot2)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = dataset$Level, y = predict(lin_reg, newdata = dataset)),
colour = 'blue') +
ggtitle('Salary vs Level (Linear Regression)')+
xlab('Level')+
ylab('Salary')
# Visualizing the Poly Regression results
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = dataset$Level, y = predict(poly_reg, newdata = dataset)),
colour = 'blue') +
ggtitle('Salary vs Level (Poly Regression)')+
xlab('Level')+
ylab('Salary')
# Predict new result with Linear Regression, lin_reg
y_pred = predict(lin_reg, data.frame(Level = 6.5))
# Predict new result with Poly Reg, poly_reg
y_poly_red = predict(poly_reg, data.frame(Level = 6.5,
Level2= 6.5^2,
Level3= 6.5^3,
Level4=6.5^4))
