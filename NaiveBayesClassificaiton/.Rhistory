ev = test_set[,10]-unname(y_pred)
ev = as.numeric(test_set[,10])-unname(y_pred)
y_pred
#RevJet
setwd("~/Desktop/RevJet")
dataset = read.csv('revjet_data.csv')
rawdataset = read.csv('revjet_data.csv')
# Encoding Cateogrical data - Creative Size
dataset$Creative.Size = factor(dataset$Creative.Size, levels = c('160x600', '300x250','300x50','300x600','320x50', '728x90'), labels = c(1, 2, 3, 4, 5, 6))
# Encoding Categorical data - Device.Type
dataset$Device.Type = factor(dataset$Device.Type, levels = c('WindowsDesktop', 'Unknown','iPhone','iPad','AppleDesktop', 'AndroidTablet','AndroidPhone'), labels = c(1, 2, 3, 4, 5, 6, 7))
# Encoding Cateogrical data - browser
dataset$Browser = factor(dataset$Browser, levels = c('AppleWebKit', 'Chrome', 'Edge', 'Firefox', 'IE', 'Safari'), labels = c(1, 2, 3, 4, 5, 6))
# Encoding Cateogrical data - Day of Week
dataset$Event.Day.of.Week = factor(dataset$Event.Day.of.Week, levels = c('1]Sunday','2]Monday','3]Tuesday','4]Wednesday','5]Thursday','6]Friday','7]Saturday'), labels = c(1,2,3,4,5,6,7))
# Encoding Cateogrical data - Day part
dataset$Event.Day.Part = factor(dataset$Event.Day.Part, levels = c('1) midnight-4AM','2) 4AM-8AM','3) 8AM-noon','4) noon-4PM','5) 4PM-8PM','6) 8PM-midnight'), labels = c(1,2,3,4,5,6))
# Encoding Cateogrical data - State
dataset$State = factor(dataset$State, levels = c('Alabama','Arizona','Arkansas','California','Colorado','Connecticut', 'Delaware', 'District of Columbia', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Karnataka', 'Kentucky','Louisiana', 'Maine','Maryland', 'Massachusetts','Michigan','Minnesota','Mississippi','Missouri', 'Montana','Nebraska', 'Nevada','New Brunswick', 'New Hampshire','New Jersey','New Mexico', 'New York', 'North Carolina', 'null', 'Ohio', 'Oklahoma','Oregon','Pennsylvania','Rhode Island', 'South Carolina', 'Tennessee','Texas', 'Utah', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming'), labels = c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50))
#36 null can be other; note: should use other parameter, alaska is not record.
# Encoding Cateogrical data - Platform
dataset$Platform = factor(dataset$Platform, levels = c('Desktop','Mobile', '_Others'), labels = c(1,2,3))
colnames(dataset)[10]="CTR"
### END of Data Preprocessing ###
# Feature Scaling
# dataset$Impressions = scale(dataset$Impressions)
# dataset$Clicks = scale(dataset$Clicks)
# Construc a new dataset for all numeric entries
d= data.frame(transform(dataset, Creative.Size =as.numeric(Creative.Size)))
d= data.frame(transform(d, Device.Type =as.numeric(Device.Type)))
d= data.frame(transform(d, Browser =as.numeric(Browser)))
d= data.frame(transform(d, Event.Day.of.Week =as.numeric(Event.Day.of.Week)))
d= data.frame(transform(d, Event.Day.Part =as.numeric(Event.Day.Part)))
d= data.frame(transform(d, State =as.numeric(State)))
d= data.frame(transform(d, Platform =as.numeric(Platform)))
d = data.frame(transform(d, CTR=as.numeric(CTR)))
library(caTools)
set.seed(123)
split = sample.split(d$CTR, SplitRatio = 0.9)
training_set = subset(d, split == TRUE)
test_set = subset(d, split == FALSE)
training_set[,1:9]=scale(training_set[,1:9])
test_set[1:9] = scale(test_set[1:9])
library(e1071)
classifier = svm(CTR ~ Creative.Size + Device.Type + Browser + Event.Day.Part,
data= training_set,
type= 'C-classification',
kernel = 'radial')
# Predicting the Test set results with SVM
y_pred = predict(classifier, newdata=test_set[-10], na.action = na.exclude)
cm = table(test_set[, 10], y_pred)
ev = test_set[,10]-c(y_pred)
MeanError = mean(ev)/100
StandardDev = sd(ev)/100
MeanError
ev=unname(ev)
MeanError = mean(ev)/100
StandardDev = sd(ev)/100
ev
mean(ev)
length(ev[ev<10])
length(ev[ev<10 AND ev>10])
length(ev[ev<10 & ev>10])
length(ev[ev<10 & ev>-10])
length(ev[ev<10 & ev>-10])/length(ev)
length(ev[ev<20 & ev>-20])/length(ev)
length(ev[ev<0.2% & ev>-0.2%])/length(ev)
length(ev[ev<0.2 & ev>-0.2])/length(ev)
length(ev[ev<0.2 & ev>-0.2])/length(ev)*length(ev)
length(ev[ev<0.2*ev & ev>-0.2*ev])/length(ev)
mean(ev)
ev
length(ev[ev<20 & ev>-20])/length(ev)
library(partykit)
imptree= ctree(Clicks/Impressions ~ Creative.Size+ Event.Day.Part, data=dataset)
png("~/desktop/revjet1.png",res=80, height=800, width=1600)
plot(imptree, gp=gpar(frontsize=1), inner_panel=node_inner,ip_args=list(abbreviate = FALSE, id = FALSE))
imptree=ctree(Clicks/Impressions~ Creative.Size+ Event.Day.Part, data=dataset, controls=ctree_control(maxdepth=15))
# Device.Type
png("~/desktop/revjet.png",res=80, height=800, width=1600)
plot(imptree, type='simple')
plot(imptree,type='simple')
dev.off()
library(partykit)
imptree= ctree(Clicks/Impressions ~ Creative.Size+ Event.Day.Part, data=dataset)
png("~/desktop/revjet1.png",res=160, height=1000, width=2000)
plot(imptree, gp=gpar(frontsize=1), inner_panel=node_inner,ip_args=list(abbreviate = FALSE, id = FALSE))
imptree=ctree(Clicks/Impressions~ Creative.Size+ Event.Day.Part, data=dataset, controls=ctree_control(maxdepth=15))
# Device.Type
png("~/desktop/revjet.png",res=160, height=1000, width=2000)
plot(imptree, type='simple')
plot(imptree,type='simple')
dev.off()
library(partykit)
imptree= ctree(Clicks/Impressions ~ Creative.Size+ Event.Day.Part, data=d)
png("~/desktop/revjet1.png",res=160, height=1000, width=2000)
plot(imptree, gp=gpar(frontsize=1), inner_panel=node_inner,ip_args=list(abbreviate = FALSE, id = FALSE))
imptree=ctree(Clicks/Impressions~ Creative.Size+ Event.Day.Part, data=d, controls=ctree_control(maxdepth=15))
# remove Device.Type
png("~/desktop/revjet.png",res=160, height=1000, width=2000)
plot(imptree, type='simple')
plot(imptree,type='simple')
dev.off()
imptree= ctree(Clicks/Impressions ~ Creative.Size+ Event.Day.Part, data=d, controls=ctree_control(maxdepth=15))
png("~/desktop/revjet1.png",res=160, height=1000, width=2000)
plot(imptree, gp=gpar(frontsize=1), inner_panel=node_inner,ip_args=list(abbreviate = FALSE, id = FALSE))
imptree=ctree(Clicks/Impressions~ Creative.Size+ Event.Day.Part, data=d, controls=ctree_control(maxdepth=15))
# remove Device.Type
png("~/desktop/revjet.png",res=160, height=1000, width=2000)
plot(imptree, type='simple')
plot(imptree,type='simple')
dev.off()
imptree=ctree(Clicks/Impressions~ Creative.Size+ Event.Day.Part, data=d, controls=ctree_control(maxdepth=15))
# remove Device.Type
png("~/desktop/revjet.png",res=100, height=1000, width=2000)
plot(imptree, type='simple')
plot(imptree,type='simple')
dev.off()
imptree=ctree(Clicks/Impressions~ Creative.Size+ Event.Day.Part, data=dataset, controls=ctree_control(maxdepth=15))
# remove Device.Type
png("~/desktop/revjet.png",res=100, height=1000, width=2000)
plot(imptree, type='simple')
plot(imptree,type='simple')
dev.off()
imptree=ctree(Clicks/Impressions~ Creative.Size+ Event.Day.Part, data=dataset, controls=ctree_control(maxdepth=15))
# remove Device.Type
png("~/desktop/revjet.png",res=100, height=1000, width=2000)
plot(imptree, type='simple')
plot(imptree,type='simple')
dev.off()
imptree=ctree(Clicks/Impressions~ Creative.Size+ Event.Day.Part, data=dataset)
# remove Device.Type
png("~/desktop/revjet.png",res=100, height=1000, width=2000)
plot(imptree, type='simple')
plot(imptree,type='simple')
dev.off()
View(dataset)
imptree=ctree(Clicks/Impressions~ Creative.Size+ Event.Day.Part, data=rawdataset)
# remove Device.Type
png("~/desktop/revjet.png",res=100, height=1000, width=2000)
plot(imptree, type='simple')
plot(imptree,type='simple')
dev.off()
imptree=ctree(Clicks/Impressions~ Creative.Size+ Event.Day.Part, data=rawdataset)
# remove Device.Type
png("~/desktop/rawrevjet.png",res=100, height=1000, width=2000)
plot(imptree, type='simple')
plot(imptree,type='simple')
dev.off()
imptree=ctree(Clicks/Impressions~ Creative.Size+ Event.Day.Part, data=dataset)
# remove Device.Type
png("~/desktop/revjet.png",res=100, height=1000, width=2000)
plot(imptree, type='simple')
plot(imptree,type='simple')
dev.off()
png("~/desktop/revjet.png",res=100, height=1000, width=2000)
plot(imptree, type='extended')
dev.off()
imptree=ctree(Clicks/Impressions~ Creative.Size+ Event.Day.Part, data=d)
png("~/desktop/revjetctreeuserfriendly.png",res=100, height=1000, width=2000)
plot(imptree, type='extended')
dev.off()
classifierIMP = svm(CTR ~ impressions,
data= training_set,
type= 'C-classification',
kernel = 'radial')
classifierIMP = svm(CTR ~ Impressions,
data= training_set,
type= 'C-classification',
kernel = 'radial')
y_pred = predict(classifier, newdata=test_set[-10], na.action = na.exclude)
y_[red]
y_pred
View(test_set)
View(d)
View(d)
scaledD=d
scaledD=d
split = sample.split(scaledD$CTR, SplitRatio = 0.9)
training_set = subset(scaledD, split == TRUE)
test_set = subset(scaledD, split == FALSE)
training_set[,1:9]=scale(training_set[,1:9])
test_set[1:9] = scale(test_set[1:9])
library(e1071)
classifier = svm(CTR ~ Creative.Size + Device.Type + Browser + Event.Day.Part,
data= training_set,
type= 'C-classification',
kernel = 'radial')
#Predicting the Test set results with SVM
y_pred = predict(classifier, newdata=test_set[-10], na.action = na.exclude)
y_pred
View(test_set)
ev = test_set[,10]-c(y_pred)
ev
Accuracy = length(ev[ev<20 & ev>-20])/length(ev)
classifierIMP = svm(CTR ~ Impressions,
data= training_set,
type= 'C-classification',
kernel = 'radial')
y_pred = predict(classifier, newdata=test_set[-10], na.action = na.exclude)
y_pred
cm = table(test_set[, 10], y_pred)
ev = test_set[,10]-c(y_pred)
ev
Accuracy = length(ev[ev<20 & ev>-20])/length(ev)
accuracy
View(test_set)
classifierIMP = svm(CTR ~ Impressions,
data= training_set,
type= 'C-classification',
kernel = 'radial')
y_pred = predict(classifier, newdata=test_set[8], na.action = na.exclude)
classifierIMP = svm(CTR ~ Impressions,
data= training_set[8],
type= 'C-classification',
kernel = 'radial')
classifierIMP = svm(CTR ~ Impressions,
data= training_set[8:10],
type= 'C-classification',
kernel = 'radial')
#Predicting the Test set results with SVM
y_pred = predict(classifier, newdata=test_set[8:10], na.action = na.exclude)
y_pred = predict(classifier, newdata=test_set[,8:10], na.action = na.exclude)
classifierIMP = svm(CTR ~ Impressions,
data= training_set,
type= 'C-classification',
kernel = 'radial')
#Predicting the Test set results with SVM
y_pred = predict(classifier, newdata=test_set[,-10], na.action = na.exclude)
y_pred
library(e1071)
classifier = svm(CTR ~ Creative.Size + Device.Type + Browser + Event.Day.Part,
data= training_set,
type= 'C-classification',
kernel = 'radial')
y_pred = predict(classifier, newdata=test_set[-10], na.action = na.exclude)
y_pred
y1=y_pred
classifier = svm(CTR ~ Impressions+ Creative.Size + Device.Type + Browser + Event.Day.Part,
data= training_set,
type= 'C-classification',
kernel = 'radial')
y_pred = predict(classifier, newdata=test_set[-10], na.action = na.exclude)
y_pred
y_pred-y1
unname(y_pred)-unname(y1)
y_pred
y1
Accuracy = length(ev[ev<20 & ev>-20])/length(ev)
ev1= test_set[,10]-c(y1)
ev-ev1
classifier = svm(CTR ~ Impressions+ Creative.Size + Device.Type + Browser + Event.Day.Part,
data= training_set,
type= 'C-classification',
kernel = 'sigmoid')
y_pred = predict(classifier, newdata=test_set[-10], na.action = na.exclude)
y_pred
ev = test_set[,10]-c(y_pred)
ev
Accuracy = length(ev[ev<20 & ev>-20])/length(ev)
classifier = svm(CTR ~ Impressions+ Creative.Size + Device.Type + Browser + Event.Day.Part,
data= training_set,
type= 'C-classification',
kernel = 'polynomial')
y_pred = predict(classifier, newdata=test_set[-10], na.action = na.exclude)
ev = test_set[,10]-c(y_pred)
Accuracy = length(ev[ev<20 & ev>-20])/length(ev)
y_pred
y1
y_pred-y1
classifier = svm(CTR ~ Impressions+ Creative.Size + Device.Type + Browser + Event.Day.Part,
data= training_set,
type= 'C-classification',
kernel = 'polynomial')
#Predicting the Test set results with SVM
y_pred = predict(classifier, newdata=test_set[-10], na.action = na.exclude)
ev = test_set[,10]-c(y_pred)
Accuracy = length(ev[ev<20 & ev>-20])/length(ev)
Accuracy = length(ev[ev<10 & ev>-10])/length(ev)
library(e1071)
classifier = svm(CTR ~ Impressions+ Creative.Size + Device.Type + Browser + Event.Day.Part,
data= training_set,
type= 'C-classification',
kernel = 'linear')
y_pred = predict(classifier, newdata=test_set[-10], na.action = na.exclude)
ev = test_set[,10]-c(y_pred)
Accuracy = length(ev[ev<20 & ev>-20])/length(ev)
Accuracy = length(ev[ev<10 & ev>-10])/length(ev)
Accuracy
library(e1071)
classifier = svm(CTR ~ Impressions+ Creative.Size + Device.Type + Browser + Event.Day.Part,
data= training_set,
type= 'C-classification',
kernel = 'radial')
y_pred = predict(classifier, newdata=test_set[-10], na.action = na.exclude)
ev = test_set[,10]-c(y_pred)
Accuracy = length(ev[ev<10 & ev>-10])/length(ev)
Accuracy = length(ev[ev<20 & ev>-20])/length(ev)
library(e1071)
classifier = svm(CTR ~ Impressions+ Creative.Size + Device.Type + Browser + Event.Day.Part,
data= training_set,
type= 'C-classificati
library(e1071)
classifier = svm(CTR ~ Impressions+ Creative.Size + Device.Type + Browser + Event.Day.Part,
data= training_set,
type= 'C-classification',
kernel = 'radial')
library(e1071)
classifier = svm(CTR ~ Impressions+ Creative.Size + Device.Type + Browser + Event.Day.Part,
data= training_set,
type= 'C-classification',
kernel = 'radial')
y_pred = predict(classifier, newdata=test_set[-10], na.action = na.exclude)
ev = test_set[,10]-c(y_pred)
Accuracy = length(ev[ev<20 & ev>-20])/length(ev)
classifier = svm(CTR ~ Impressions+ Creative.Size + Device.Type + Browser + Event.Day.Part,
data= training_set,
type= 'nu-classification',
kernel = 'radial')
Accuracy = length(ev[ev<25 & ev>-25])/length(ev)
Accuracy = length(ev[ev<50 & ev>-50])/length(ev)
Accuracy = length(ev[ev<25 & ev>-25])/length(ev)
Accuracy = length(ev[ev<30 & ev>-30])/length(ev)
library(e1071)
linearSVMclassifier = svm(CTR ~ Impressions+ Creative.Size + Device.Type + Browser + Event.Day.Part,
data= training_set,
type= 'C-classification',
kernel = 'linear')
linear_ev = test_set[,10]-c(y_pred)
ev=unname(ev)
#So how accurate is our model within 0.30%/0.20%/0.10% ClickThrough Rate?
linearSVMAccuracy030CTR = length(linear_ev[linear_ev<30 & linear_ev>-30])/length(linear_ev)
linearSVMAccuracy020CTR = length(linear_ev[linear_ev<20 & linear_ev>-20])/length(ev)
linearSVMAccuracy010CTR = length(linear_ev[linear_ev<10 & linear_ev>-10])/length(ev)
# For Linear, 76.85
library(partykit)
imptree=ctree(Clicks/Impressions~ Creative.Size+ Event.Day.Part, data=dataset)
# remove Device.Type
png("~/desktop/revjetctree.png",res=100, height=1000, width=2000)
plot(imptree, type='extended')
imptree=ctree(Clicks/Impressions~ Creative.Size+ Event.Day.Part, data=dataset)
png("~/desktop/revjetctreeuserfriendly.png",res=100, height=1000, width=2000)
plot(imptree, type='extended')
dev.off()
imptree=ctree(Clicks/Impressions~ Creative.Size+ Event.Day.Part, data=dataset)
# remove Device.Type
png("~/desktop/revjetctree.png",res=100, height=1000, width=2000)
plot(imptree, type='extended')
imptree=ctree(Clicks/Impressions~ Creative.Size+ Event.Day.Part, data=dataset)
dev.off()
png("~/desktop/revjetctreeuserfriendly.png",res=100, height=1000, width=2000)
plot(imptree, type='extended')
dev.off()
View(dataset)
View(d)
View(rawdataset)
imptree=ctree(Clicks/Impressions~ Creative.Size+ Event.Day.Part, data=dataset)
png("~/desktop/revjetctree.png",res=100, height=1000, width=2000)
plot(imptree, type='extended')
dev.off()
## User-friendly tree in PNG
imptree=ctree(Clicks/Impressions~ Creative.Size+ Event.Day.Part, data=rawdataset)
png("~/desktop/revjetctreeuserfriendly.png",res=100, height=1000, width=2000)
plot(imptree, type='extended')
dev.off()
setwd("~/Desktop/Ex_Files_DSF_DataMining/Machine-Learning-Udemy/NaiveBayesClassificaiton")
#Naive Bayes
setwd("~/Desktop/Ex_Files_DSF_DataMining/Machine-Learning-Udemy/NaiveBayesClassificaiton")
# Importing the dataset
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[3:5]
# Encoding the target feature as factor
dataset$Purchased = factor(dataset$Purchased, levels = c(0, 1))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_set[-3] = scale(training_set[-3])
test_set[-3] = scale(test_set[-3])
library(e1071)
classifier = naiveBayes( x = training_set[-3], y= training_set$Purchased)
y_pred = predict(classifier, newdata=test_set[-3])
y_pred
cm = table(test_set[, 3], y_pred)
cm
#Naive Bayes
setwd("~/Desktop/Ex_Files_DSF_DataMining/Machine-Learning-Udemy/NaiveBayesClassificaiton")
# Importing the dataset
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[3:5]
# Encoding the target feature as factor
# dataset$Purchased = factor(dataset$Purchased, levels = c(0, 1))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_set[-3] = scale(training_set[-3])
test_set[-3] = scale(test_set[-3])
# Fitting Naive Bayes Classifier  to the Training set
library(e1071)
classifier = naiveBayes( x = training_set[-3], y= training_set$Purchased)
y_pred = predict(classifier, newdata=test_set[-3])
y_pred
#Naive Bayes
setwd("~/Desktop/Ex_Files_DSF_DataMining/Machine-Learning-Udemy/NaiveBayesClassificaiton")
# Importing the dataset
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[3:5]
# Encoding the target feature as factor
dataset$Purchased = factor(dataset$Purchased, levels = c(0, 1))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_set[-3] = scale(training_set[-3])
test_set[-3] = scale(test_set[-3])
# Fitting Naive Bayes Classifier  to the Training set
library(e1071)
classifier = naiveBayes( x = training_set[-3], y= training_set$Purchased)
# Predicting the Test set results
y_pred = predict(classifier, newdata=test_set[-3])
#Naive Bayes
setwd("~/Desktop/Ex_Files_DSF_DataMining/Machine-Learning-Udemy/NaiveBayesClassificaiton")
# Importing the dataset
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[3:5]
# Encoding the target feature as factor
# Recognize Purchased as factor
dataset$Purchased = factor(dataset$Purchased, levels = c(0, 1))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_set[-3] = scale(training_set[-3])
test_set[-3] = scale(test_set[-3])
library(e1071)
classifier = naiveBayes( x = training_set[-3], y= training_set$Purchased)
y_pred = predict(classifier, newdata=test_set[-3])
y_pred
cm = table(test_set[, 3], y_pred)
cm
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, newdata=grid_set)
plot(set[, -3],
main = 'Naive Bayes Classifier (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
#Naive Bayes
setwd("~/Desktop/Ex_Files_DSF_DataMining/Machine-Learning-Udemy/NaiveBayesClassificaiton")
# Importing the dataset
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[3:5]
# Encoding the target feature as factor
# Recognize Purchased as factor
dataset$Purchased = factor(dataset$Purchased, levels = c(0, 1))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_set[-3] = scale(training_set[-3])
test_set[-3] = scale(test_set[-3])
# Fitting Naive Bayes Classifier  to the Training set
library(e1071)
classifier = naiveBayes( x = training_set[-3], y= training_set$Purchased)
# Predicting the Test set results
y_pred = predict(classifier, newdata=test_set[-3])
# Making the Confusion Matrix
cm = table(test_set[, 3], y_pred)
# Visualising the Training set results
# install.packages('ElemStatLearn')
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, newdata=grid_set)
plot(set[, -3],
main = 'Naive Bayes Classifier (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
