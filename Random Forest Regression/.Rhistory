6-3
2+5
winners <- read.delim(pipe('pbpaste'))
View(winners)
View(winners)
winners
winners <- read.delim(pipe('pbpaste'))
View(winners)
winners
x+y
x<- 1
y<-2
x+y
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
Oscar
Romeo+Oscar
Calvin<-Romeo+Oscar
Calvin<-x
Oscar
source('~/.active-rstudio-document', echo=TRUE)
Juliet-Romeo
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/Downloads/Ex_Files_Intro_Data_Science/DataScienceExcercise_github/Ensembles with Random Forest.R')
source('~/.active-rstudio-document')
install.packages("randomForest")
install.packages("party")  # Install party
library(datasets)          # Load built-in datasets
library(party)             # Load party
head(iris)
iris.ct <- ctree(Species~., data=iris)
plot(iris.ct)
table(predict(iris.ct),iris$Species)
head(mtcars)
car.rt<-ctree(mpg~cyl+disp+hp+drat+wt+qsec, data=mtcars)
plot(car.rt2)
plot(car.rt3)
plot(car.rt)
table(predict(car.rt),mtcars$mpg)
data(HouseVotes84, package = "mlbench")
vote <- HouseVotes84
head(vote)
set.seed(1984)
set.seed(1984)
vote.split <- sample(2, nrow(vote),
replace = TRUE,
prob = c(2/3, 1/3))
vote.train <- vote[vote.split == 1, ]
vote.test  <- vote[vote.split == 2, ]
# ==========================================================
# Build and test classifier
# nbc= naive Bayes Classifier
# ==========================================================
nbc <- naiveBayes(Class ~ ., data = vote.train)
install.packages("e1071")
install.packages("mlbench")
library(e1071)
library(mlbench)
# ==========================================================
# Prepare data: HouseVotes84
# Using "HouseVotes84" from mlbench package
# ==========================================================
data(HouseVotes84, package = "mlbench")
vote <- HouseVotes84
head(vote)
# Split data into training set (2/3) and testing set (1/3)
# set.seed()to have consistency
# Trying to categorize whether one person is democrat or republican
# Split data with 2 sets: a training set and a testing set (WITH vote.split)
set.seed(1984)
vote.split <- sample(2, nrow(vote),
replace = TRUE,
prob = c(2/3, 1/3))
vote.train <- vote[vote.split == 1, ]
vote.test  <- vote[vote.split == 2, ]
head(vote.train)
head(vote.test)
nbc <- naiveBayes(Class ~ ., data = vote.train)
nbc  # Examine the classifier
table(predict(nbc, vote.train[, -1]), vote.train[, 1])
round(prop.table(table(predict(nbc, vote.train[, -1]),
vote.train[, 1]),
1),  # Row percentages (2 = column)
2) * 100        # Round to 2 digits, remove decimals
table(predict(nbc, vote.test[, -1]), vote.test[, 1])
round(prop.table(table(predict(nbc, vote.test[, -1]),
vote.test[, 1]),
1),  # Row percentages (2 = column)
2) * 100        # Round to 2 digits, remove decimals
rm(list = ls())
detach("package:e1071", unload = TRUE)
detach("package:mlbench", unload = TRUE)
cat("\014")
install.packages('neuralnet')  # Install neuralnet
library(neuralnet)             # Load neuralnet
set.seed(1202)                             # Set seed
train.x <- sample(1:100, 50, replace = T)
head(train.x)
train.x
train.y <- sqrt(train.x)
train y
train.y
train.xy <- as.data.frame(cbind(train.x, train.y))
head(train.xy)
net.sqrt <- neuralnet(train.y ~ train.x,
train.xy,
hidden = 10,
threshold = 0.01)
plot(net.sqrt)
hidden = 20,
net.sqrt <- neuralnet(train.y ~ train.x,
train.xy,
hidden = 20,
threshold = 0.01)
plot(net.sqrt)
test.x <- as.data.frame((1:10)^2)
test.y <- compute(net.sqrt, test.x)
test.y
test.x
test.y
net.table <- cbind(test.x,
sqrt(test.x),
round(test.y$net.result, 2))
net.table
net.table <- cbind(test.x,
sqrt(test.x),
round(test.y$net.result, 3))
colnames(net.table) <- c("X","Y-Exp","Y-ANN")
net.table  # Display table
test.trainx <- comput(net.sqrt, train.x)
test.trainx <- compute(net.sqrt, train.x)
test.trainx
train.y
#
test.trainx
train.y
net.table<- cbind(train.x, train.y, round(test.trainx$net.result,3))
net.table1<- cbind(train.x, train.y, round(test.trainx$net.result,3))
net.table <- cbind(test.x,
sqrt(test.x),
round(test.y$net.result, 3))
net.table1
net.table <- cbind(test.x,
sqrt(test.x),
round(test.y$net.result, 3))
colnames(net.table) <- c("X","Y-Exp","Y-ANN")
#Rename the column name
net.table  # Display table
net.table
test.y
print("Hello World!")
print("Hello World")
source('~/Desktop/RevJet/revjet.R')
x_grid = seq(min(dataset$Impressions), max(dataset$Impressions), 0.01)
ggplot() +
geom_point(aes(x = dataset$Impressions, y = dataset$Clicks),
colour = 'red') +
geom_line(aes(x = x_grid, y = predict(impressionsregressor, newdata = data.frame(Level = x_grid))),
colour = 'blue') +
ggtitle('Impressions vs Clicks (Multiple Linear Regression Model)') +
xlab('Impressions') +
ylab('Clicks')
summary(impressionsregressor)
library(ggplot2)
x_grid = seq(min(dataset$Impressions), max(dataset$Impressions), 0.01)
ggplot() +
geom_point(aes(x = dataset$Impressions, y = dataset$Clicks),
colour = 'red') +
geom_line(aes(x = x_grid, y = predict(impressionsregressor, newdata = data.frame(Level = x_grid))),
colour = 'blue') +
ggtitle('Impressions vs Clicks (Multiple Linear Regression Model)') +
xlab('Impressions') +
ylab('Clicks')
x_grid = seq(min(dataset$Impressions), max(dataset$Impressions), 0.01)
ggplot() +
geom_point(aes(x = dataset$Impressions, y = dataset$Clicks),
colour = 'red') +
geom_line(aes(x = x_grid, y = predict(impressionsregressor, newdata = data.frame(Impressions = x_grid))),
colour = 'blue') +
ggtitle('Impressions vs Clicks (Multiple Linear Regression Model)') +
xlab('Impressions') +
ylab('Clicks')
# install.packages('ggplot2')
library(ggplot2)
x_grid = seq(min(dataset$Impressions), max(dataset$Impressions), 0.01)
ggplot() +
geom_point(aes(x = dataset$Impressions, y = dataset$Clicks),
colour = 'red') +
geom_line(aes(x = x_grid, y = predict(impressionsregressor, newdata = data.frame(dataset$Impressions = x_grid))),
colour = 'blue') +
ggtitle('Impressions vs Clicks (Multiple Linear Regression Model)') +
xlab('Impressions') +
ylab('Clicks')
source('~/Desktop/Ex_Files_DSF_DataMining/Machine-Learning-Udemy/Random Forest Regression/RandomForestRegression.R')
# Random Forest Regression
# Importing the dataset
dataset = read.csv('Position_Salaries.csv')
dataset = dataset[2:3]
# Fitting the Random Forest Regression Model to the dataset
# install.packages('randomForest')
library(randomForest)
regressor = randomForest(x=dataset[1],y=dataset$Salary, ntrees = 10)
# Random Forest Regression
# Importing the dataset
dataset = read.csv('Position_Salaries.csv')
dataset = dataset[2:3]
# Fitting the Random Forest Regression Model to the dataset
# install.packages('randomForest')
library(randomForest)
regressor = randomForest(x=dataset[1],y=dataset$Salary, ntrees = 10)
#Dataset$salary vector; dataset[1] dataframe; with 10 trees
# Predicting a new result
y_pred = predict(regressor, data.frame(Level = 6.5))
library(ggplot2)
# Visualising the Regression Model results (for higher resolution and smoother curve)
# install.packages('ggplot2')
library(ggplot2)
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.01)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),
colour = 'blue') +
ggtitle('Truth or Bluff (Regression Model)') +
xlab('Level') +
ylab('Salary')
View(dataset)
dataset = read.csv('Position_Salaries.csv')
dataset = dataset[2:3]
setwd("~/Desktop/Ex_Files_DSF_DataMining/Machine-Learning-Udemy/Random Forest Regression")
dataset = read.csv('Position_Salaries.csv')
dataset = dataset[2:3]
# Random Forest Regression
library(randomForest)
set.seed(1234) # Set Seed to have consistent result
regressor = randomForest(x=dataset[1],y=dataset$Salary, ntrees = 10)
y_pred = predict(regressor, data.frame(Level = 6.5))
# Random Forest Regression
# Importing the dataset
dataset = read.csv('Position_Salaries.csv')
dataset = dataset[2:3]
# Fitting the Random Forest Regression Model to the dataset
# install.packages('randomForest')
library(randomForest)
set.seed(1234) # Set Seed to have consistent result
regressor = randomForest(x=dataset[1],y=dataset$Salary, ntrees = 10)
#Dataset$salary vector; dataset[1] dataframe; with 10 trees
# Predicting a new result
y_pred = predict(regressor, data.frame(Level = 6.5))
library(ggplot2)
# Visualising the Random Forest Regression Model results (for higher resolution and smoother curve)
# install.packages('ggplot2')
library(ggplot2)
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.01)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),
colour = 'blue') +
ggtitle('Truth or Bluff (Random Forest Regression Model)') +
xlab('Level') +
ylab('Salary')
# Random Forest Regression
# Importing the dataset
dataset = read.csv('Position_Salaries.csv')
dataset = dataset[2:3]
# Fitting the Random Forest Regression Model to the dataset
# install.packages('randomForest')
library(randomForest)
set.seed(1234) # Set Seed to have consistent result
regressor = randomForest(x=dataset[1],y=dataset$Salary, ntrees = 100)
#Dataset$salary vector; dataset[1] dataframe; with 10 trees
# Predicting a new result
y_pred = predict(regressor, data.frame(Level = 6.5))
library(ggplot2)
# Visualising the Random Forest Regression Model results (for higher resolution and smoother curve)
# install.packages('ggplot2')
library(ggplot2)
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.01)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),
colour = 'blue') +
ggtitle('Truth or Bluff (Random Forest Regression Model)') +
xlab('Level') +
ylab('Salary')
source('~/.active-rstudio-document')
library(ggplot2)
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.01)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),
colour = 'blue') +
ggtitle('Truth or Bluff (Random Forest Regression Model)') +
xlab('Level') +
ylab('Salary')
